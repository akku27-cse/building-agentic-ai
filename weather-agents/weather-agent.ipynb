{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177a1400-e0f8-478c-b49e-b0992e2e7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19e49d1-517a-4b15-b134-3f1a686e7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0e35d1-006b-4684-93c2-08543829e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b47a347-6272-4b71-880e-4e325e26ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835fc0b8-4917-42fe-bf5a-68a200ab53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc94aa4-b115-4871-a356-8ab3b6050fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY loaded: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "env_path = r\"E:\\weather-agent\\.env\"\n",
    "load_dotenv(env_path)\n",
    "print(\"GOOGLE_API_KEY loaded:\", bool(os.getenv(\"GOOGLE_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8329d42-0ae3-4f50-97c6-c09543ce3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9eda66-41b6-48dd-9015-2e9d37123880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Santu! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define a simple prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"Hello, {name}! How can I help you today?\"\n",
    ")\n",
    "\n",
    "# Generate the prompt by filling in the variable\n",
    "formatted_prompt = prompt_template.format(name=\"Santu\")\n",
    "\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e720a3bc-c974-4418-8cd4-c6c7132ebf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Nepal is **Kathmandu**.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Use one of the models from your list_models() output\n",
    "chat_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",  # Matches your output: models/gemini-2.5-flash\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(\"What is the capital of the Nepal?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237aba1c-eba2-47ea-8413-6d161dd7ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI Training Consultant, I've observed that the landscape of Deep Learning is evolving at an unprecedented pace. To equip individuals for success in this dynamic field, training must go beyond foundational concepts to embrace the cutting-edge advancements that are shaping the industry.\n",
      "\n",
      "Here is a list of essential Deep Learning topics, categorized for clarity, along with why each is crucial for staying relevant in today's AI environment:\n",
      "\n",
      "---\n",
      "\n",
      "## Essential Deep Learning Topics for Current AI Landscape\n",
      "\n",
      "### I. Foundational Concepts & Tools (The Bedrock)\n",
      "\n",
      "1.  **Neural Network Fundamentals & Architectures:**\n",
      "    *   **Topics:** Perceptrons, Multi-Layer Perceptrons (MLPs), Activation Functions (ReLU, GELU, Swish), Loss Functions (Cross-Entropy, MSE), Optimizers (SGD, Adam, Adagrad, RMSprop, AdamW), Backpropagation.\n",
      "    *   **Why it's Important:** These are the absolute building blocks. Even with highly abstracted frameworks, a deep understanding of these fundamentals is critical for debugging, custom model design, and understanding the core mechanics of how neural networks learn. Recent advancements often tweak or combine these elements in novel ways.\n",
      "\n",
      "2.  **Deep Learning Frameworks (PyTorch & TensorFlow/Keras):**\n",
      "    *   **Topics:** Hands-on proficiency with at least one major framework (PyTorch is currently dominant in research and gaining significant ground in industry due to its flexibility and Pythonic nature; TensorFlow/Keras remain strong for production deployments). Understanding computational graphs, custom layers, and model checkpoints.\n",
      "    *   **Why it's Important:** These frameworks are the lingua franca of Deep Learning implementation. Proficiency allows rapid prototyping, efficient development, and leveraging community-contributed models and tools. Staying updated on their features and best practices is essential.\n",
      "\n",
      "3.  **Data Preprocessing, Augmentation & Management:**\n",
      "    *   **Topics:** Data cleaning, normalization, standardization, handling missing values, encoding categorical data, image/text/audio augmentation techniques (e.g., CutMix, Mixup, SpecAugment, random cropping, token shuffling), dataset versioning.\n",
      "    *   **Why it's Important:** \"Garbage in, garbage out\" remains paramount. High-quality, diverse data is the lifeblood of successful deep learning models. Advanced augmentation techniques are crucial for improving model robustness, generalizing better, and reducing reliance on massive labeled datasets, especially relevant in resource-constrained scenarios.\n",
      "\n",
      "4.  **Regularization & Optimization Techniques:**\n",
      "    *   **Topics:** Dropout, L1/L2 Regularization, Batch Normalization, Layer Normalization, Group Normalization, Gradient Clipping, Learning Rate Schedulers (e.g., Cosine Annealing, ReduceLROnPlateau).\n",
      "    *   **Why it's Important:** Preventing overfitting and ensuring stable, efficient training are constant challenges. Modern deep learning models are incredibly complex; mastering these techniques is essential for training high-performing, generalized models that work well on unseen data. Layer Norm and Batch Norm are critical components in state-of-the-art architectures.\n",
      "\n",
      "### II. Core Deep Learning Architectures & Paradigms (The Workhorses)\n",
      "\n",
      "5.  **Convolutional Neural Networks (CNNs):**\n",
      "    *   **Topics:** Convolutional layers, pooling layers, various CNN architectures (ResNet, Inception, VGG, MobileNet, EfficientNet), attention mechanisms in CNNs.\n",
      "    *   **Why it's Important:** While Transformers are encroaching, CNNs remain fundamental for computer vision tasks and are highly efficient for image processing. Understanding their strengths, weaknesses, and common architectural patterns is vital for image and video analysis. Many advanced vision models still incorporate CNN principles.\n",
      "\n",
      "6.  **Transformers & Attention Mechanisms:**\n",
      "    *   **Topics:** Self-attention, multi-head attention, encoder-decoder architectures, positional encodings, prominent Transformer variants (BERT, GPT, T5, ViT, Swin Transformer), architecture scaling.\n",
      "    *   **Why it's Important:** **This is arguably the most critical topic.** Transformers have revolutionized NLP, Computer Vision (Vision Transformers), and even audio processing. They are the backbone of all modern Large Language Models (LLMs) and foundation models. Deep understanding of their mechanics, variants, and scaling properties is non-negotiable for anyone working in advanced AI.\n",
      "\n",
      "7.  **Generative Models (GANs, VAEs, Diffusion Models):**\n",
      "    *   **Topics:** Generative Adversarial Networks (GANs) - architecture, training challenges, variants (CycleGAN, StyleGAN); Variational Autoencoders (VAEs); **Diffusion Models (DDPM, Latent Diffusion)** - theoretical foundations, sampling processes, conditional generation.\n",
      "    *   **Why it's Important:** Generative AI is exploding. Diffusion models, in particular, are at the forefront of image, audio, and even video generation (e.g., DALL-E 3, Midjourney, Stable Diffusion). Understanding these models is key for content creation, data augmentation, anomaly detection, and synthetic data generation.\n",
      "\n",
      "### III. Advanced Techniques & Paradigms (The Cutting Edge)\n",
      "\n",
      "8.  **Transfer Learning & Fine-tuning:**\n",
      "    *   **Topics:** Pre-trained models, feature extraction vs. fine-tuning, domain adaptation, few-shot learning, prompt engineering for LLMs.\n",
      "    *   **Why it's Important:** Training models from scratch is computationally expensive and data-intensive. Transfer learning allows leveraging vast pre-trained models, significantly reducing training time and data requirements, making AI accessible for a wider range of applications. Fine-tuning and prompt engineering are the primary ways to adapt powerful LLMs to specific tasks.\n",
      "\n",
      "9.  **Self-Supervised Learning (SSL):**\n",
      "    *   **Topics:** Contrastive learning (SimCLR, MoCo), masked autoencoders (MAE), infomax principles, pseudo-labeling.\n",
      "    *   **Why it's Important:** SSL allows models to learn powerful representations from unlabeled data, which is abundant. This is a game-changer for situations where labeled data is scarce or expensive, and it's a core component in how many powerful foundation models (like BERT and vision-language models) are initially trained.\n",
      "\n",
      "10. **Multi-modal Learning:**\n",
      "    *   **Topics:** Architectures that combine different data types (e.g., vision-language models like CLIP, DALL-E, BLIP), joint embeddings, cross-modal attention.\n",
      "    *   **Why it's Important:** The real world is multi-modal. Building AI systems that can understand and interact across different modalities (text, images, audio, video) is crucial for more human-like intelligence, richer user experiences, and complex reasoning tasks.\n",
      "\n",
      "11. **Graph Neural Networks (GNNs):**\n",
      "    *   **Topics:** Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), message passing, applications in social networks, drug discovery, recommendation systems.\n",
      "    *   **Why it's Important:** Many real-world datasets are inherently structured as graphs (e.g., social networks, molecular structures, knowledge graphs). GNNs are specifically designed to process such data, enabling powerful insights and predictions that traditional deep learning models struggle with.\n",
      "\n",
      "### IV. Practical & Responsible AI (From Lab to Life)\n",
      "\n",
      "12. **Hyperparameter Tuning & Experiment Management:**\n",
      "    *   **Topics:** Grid search, random search, Bayesian optimization, evolutionary algorithms, tools for experiment tracking (e.g., MLflow, Weights & Biases, Comet ML).\n",
      "    *   **Why it's Important:** Optimizing model performance requires systematic experimentation. Effective hyperparameter tuning and robust experiment tracking are vital for managing complex projects, reproducing results, and iterating efficiently towards better models.\n",
      "\n",
      "13. **Model Deployment & MLOps Principles:**\n",
      "    *   **Topics:** Model serialization (ONNX, TorchScript), containerization (Docker), deployment platforms (Kubernetes, AWS SageMaker, Azure ML, Google AI Platform), monitoring (data drift, model drift), A/B testing, continuous integration/delivery for ML (CI/CD/CM).\n",
      "    *   **Why it's Important:** A model is only valuable when it's in production and serving real users. MLOps bridges the gap between research and production, ensuring models are reliable, scalable, maintainable, and continuously improving in real-world environments. This is where significant industry demand lies.\n",
      "\n",
      "14. **Explainable AI (XAI) & Interpretability:**\n",
      "    *   **Topics:** Feature importance (SHAP, LIME), saliency maps (Grad-CAM), attention visualization, model distillation, counterfactual explanations.\n",
      "    *   **Why it's Important:** As AI becomes more pervasive, understanding *why* a model makes a particular decision is crucial for trust, debugging, identifying bias, and meeting regulatory requirements (e.g., GDPR, ethical guidelines). It's no longer enough for models to just be accurate; they must also be interpretable.\n",
      "\n",
      "15. **AI Ethics, Bias, & Fairness:**\n",
      "    *   **Topics:** Sources of bias in data and models, fairness metrics (demographic parity, equalized odds), debiasing techniques, privacy-preserving AI (differential privacy, federated learning), responsible AI development guidelines.\n",
      "    *   **Why it's Important:** Addressing ethical concerns is paramount. Unchecked AI models can perpetuate and amplify societal biases, leading to discriminatory outcomes. Learning to identify, measure, and mitigate bias is a moral imperative and increasingly a legal and business requirement for any AI practitioner.\n",
      "\n",
      "---\n",
      "\n",
      "### Conclusion & Learning Approach:\n",
      "\n",
      "To effectively learn these topics, I recommend a multi-faceted approach:\n",
      "\n",
      "1.  **Strong Theoretical Foundation:** Understand the mathematical and algorithmic underpinnings.\n",
      "2.  **Hands-on Implementation:** Code models from scratch for core concepts, then use frameworks for advanced architectures.\n",
      "3.  **Real-world Projects:** Apply learned concepts to diverse datasets and problems, mimicking industry challenges.\n",
      "4.  **Stay Updated:** Follow leading research (e.g., arXiv, major conferences like NeurIPS, ICML, ICLR, CVPR, ACL), influential blogs, and open-source projects.\n",
      "5.  **Community Engagement:** Participate in online forums, hackathons, and collaborate with peers.\n",
      "\n",
      "By focusing on these areas, individuals will be well-equipped to contribute meaningfully to the rapidly evolving field of Deep Learning and drive innovation in AI.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Initialize the Gemini model instead of OpenAI\n",
    "# Using 'gemini-2.5-flash' from your available models list\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "learn_template = \"\"\"\n",
    "I want you to act as a consultant for a AI training\n",
    "Return a list of topics and why it is important to learn in given area of AI\n",
    "The description should be relevant to recent advancement in AI\n",
    "What are some good topics to learn in {AI_topic}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"AI_topic\"],\n",
    "    template=learn_template,\n",
    ")\n",
    "\n",
    "# 2. Modern LCEL Chain (Replaces legacy LLMChain)\n",
    "# This pipes the prompt into the llm, then parses the output as a string\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "\n",
    "description = \"Deep learning\"\n",
    "\n",
    "# 3. Run the chain\n",
    "# In LCEL, we use .invoke() instead of .run()\n",
    "response = chain.invoke({\"AI_topic\": description})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150fe540-4022-41fe-8279-ee56de35bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': 'In Bagmati, Nepal, the current weather is sunny with a real-time temperature of 19Â°C.', 'extras': {'signature': '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'}}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import Tool\n",
    "# Modern import for 2025\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1. Initialize Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 2. Define custom tool\n",
    "def my_tool_function(query: str) -> str:\n",
    "    return f\"Tool response: {query}\"\n",
    "\n",
    "my_tool = Tool.from_function(\n",
    "    func=my_tool_function, \n",
    "    name=\"simple_tool\", \n",
    "    description=\"Use this for simple responses.\"\n",
    ")\n",
    "\n",
    "# 3. Setup Tools\n",
    "ddg_search = DuckDuckGoSearchRun()\n",
    "tools = [ddg_search, my_tool]\n",
    "\n",
    "# 4. Create the Agent (New v1.0 Standard)\n",
    "# This creates a production-ready agent without needing AgentExecutor\n",
    "agent = create_agent(\n",
    "    llm, \n",
    "    tools=tools, \n",
    "    system_prompt=\"You are a helpful assistant. Use tools for real-time info.\"\n",
    ")\n",
    "\n",
    "# 5. Run the agent\n",
    "# Using modern .invoke() syntax\n",
    "response = agent.invoke({\"messages\": [(\"user\", \"What's the weather like today in nepal?\")]})\n",
    "\n",
    "# Print the last message from the agent\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59549e49-f3e2-4d28-9767-1bb3621d0b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "853ca5f4-fa96-42f6-b698-287ce7256690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.2.0\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://docs.langchain.com/\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-community\n",
      "Version: 0.4.1\n",
      "Summary: Community contributed LangChain integrations.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: aiohttp, dataclasses-json, httpx-sse, langchain-classic, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "---\n",
      "Name: duckduckgo_search\n",
      "Version: 8.1.1\n",
      "Summary: Search for words, documents, images, news, maps and text translation using the DuckDuckGo.com search engine.\n",
      "Home-page: https://github.com/deedy5/duckduckgo_search\n",
      "Author: deedy5\n",
      "Author-email: \n",
      "License: MIT License\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: click, lxml, primp\n",
      "Required-by: \n",
      "---\n",
      "Name: python-dotenv\n",
      "Version: 1.2.1\n",
      "Summary: Read key-value pairs from a .env file and set them as environment variables\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Saurabh Kumar <me+github@saurabh-kumar.com>\n",
      "License: \n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: pydantic-settings\n",
      "---\n",
      "Name: requests\n",
      "Version: 2.32.5\n",
      "Summary: Python HTTP for Humans.\n",
      "Home-page: https://requests.readthedocs.io\n",
      "Author: Kenneth Reitz\n",
      "Author-email: me@kennethreitz.org\n",
      "License: Apache-2.0\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: certifi, charset_normalizer, idna, urllib3\n",
      "Required-by: google-api-core, google-genai, langchain-classic, langchain-community, langsmith, requests-toolbelt\n",
      "---\n",
      "Name: ddgs\n",
      "Version: 9.10.0\n",
      "Summary: Dux Distributed Global Search. A metasearch library that aggregates results from diverse web search services.\n",
      "Home-page: https://github.com/deedy5/ddgs\n",
      "Author: deedy5\n",
      "Author-email: \n",
      "License: \n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: click, fake-useragent, httpx, lxml, primp\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-google-genai\n",
      "Version: 4.1.2\n",
      "Summary: An integration package connecting Google's genai package and LangChain\n",
      "Home-page: https://docs.langchain.com/oss/python/integrations/providers/google\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: filetype, google-genai, langchain-core, pydantic\n",
      "Required-by: \n",
      "---\n",
      "Name: google-generativeai\n",
      "Version: 0.8.6\n",
      "Summary: Google Generative AI High level API client library and tools.\n",
      "Home-page: https://github.com/google/generative-ai-python\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: E:\\weather-agent-implement\\myenv\\Lib\\site-packages\n",
      "Requires: google-ai-generativelanguage, google-api-core, google-api-python-client, google-auth, protobuf, pydantic, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain langchain-community duckduckgo-search python-dotenv requests ddgs langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a30a9-742d-4d65-8f49-e094670f3a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
